{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95965cfd-c4e0-43dc-8579-a775e65ddeb6",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15078cc-f4dd-46b5-8df8-b7366ab1cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/srabin/spark-3.5.1-bin-hadoop3')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760bf41c-6fbd-4efe-a21c-6dbc8238fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad3fa99-ab30-42f1-bca7-295eebcb2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/06 16:54:32 WARN Utils: Your hostname, DESKTOP-P0KTK6U resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/08/06 16:54:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/06 16:54:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/08/06 16:54:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/08/06 16:54:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/08/06 16:54:33 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('miss').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a018a4e4-f5c9-4477-982f-62aa04742372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('ContainsNull.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd015d0-78b5-4cdd-973d-076e22535a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp2| NULL| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e5e7f2-caae-4273-98f4-872eccdce62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40cb72db-ed04-43b1-8f28-e3e9f2104645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can specify a threshold\n",
    "# the row needs to have at least two null values to be dropped\n",
    "df.na.drop(thresh = 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4facaff6-4a2f-4bf6-94dd-4b009c86a0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how = 'any').show() # only drop if there is any null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926ef70f-4344-4eea-a05e-a904be98c2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp2| NULL| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how = 'all').show() # only drop if all values in a row are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6caed56e-7d8b-40a6-876d-03f37dff08e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset = ['Sales']).show() #only missing sales matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe2d2c02-2c20-462d-adf1-b08b89fe8515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a965551e-dacf-4f43-b9cf-00195ca7748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+\n",
      "|  Id|      Name|Sales|\n",
      "+----+----------+-----+\n",
      "|emp1|      John| NULL|\n",
      "|emp2|FILL VALUE| NULL|\n",
      "|emp3|FILL VALUE|345.0|\n",
      "|emp4|     Cindy|456.0|\n",
      "+----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('FILL VALUE').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "005356b7-af7d-4854-b060-03f4e62481be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|  0.0|\n",
      "|emp2| NULL|  0.0|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116b307d-8795-4671-a5e9-6ba207297216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|  Id|   Name|Sales|\n",
      "+----+-------+-----+\n",
      "|emp1|   John| NULL|\n",
      "|emp2|No Name| NULL|\n",
      "|emp3|No Name|345.0|\n",
      "|emp4|  Cindy|456.0|\n",
      "+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('No Name', subset = ['Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0f58711-dcdd-4e4c-9a5b-5d1e4d78aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill values with mean values\n",
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b86c91cf-13f0-42a2-b0ef-00a9512d45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = df.select(mean(df['Sales'])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "474ba8be-10a2-4b0d-bfdf-8a8109acbe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sales = mean_val[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6549837-2fd8-423b-8f3b-cc6f0eea4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| NULL|400.5|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(mean_sales, ['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2e71799-7861-403f-849c-d1f47a33114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it all in one line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "989c20cb-55aa-4f9f-9a86-492a3076bb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| NULL|400.5|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(df.select(mean(df['Sales'])).collect()[0][0], ['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1d48a-eb72-476e-a0d7-e2657f616644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
